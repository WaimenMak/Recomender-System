{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create movie_url.csv \n",
    "link_df = pd.read_csv(\"links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114709\n",
       "1        113497\n",
       "2        113228\n",
       "3        114885\n",
       "4        113041\n",
       "         ...   \n",
       "9737    5476944\n",
       "9738    5914996\n",
       "9739    6397426\n",
       "9740    8391976\n",
       "9741     101726\n",
       "Name: imdbId, Length: 9742, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df[\"imdbId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLink(movie_id): \n",
    "    baseUrl = 'http://www.imdb.com/title/tt'\n",
    "    ending = \"/?ref_=fn_al_tt_1\"\n",
    "    if len(str(movie_id))==6: \n",
    "        movie_id = \"0\" + str(movie_id) \n",
    "    else: \n",
    "        movie_id = str(movie_id)\n",
    "    return baseUrl + movie_id + ending\n",
    "\n",
    "def generateMovieId(movie_id): \n",
    "    baseUrl = 'tt'\n",
    "    if len(str(movie_id))==6: \n",
    "        movie_id = \"0\" + str(movie_id) \n",
    "    else: \n",
    "        movie_id = str(movie_id)\n",
    "    return baseUrl + movie_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generateLink' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/603797576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlink_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerateLink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"imdbId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tconst\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerateMovieId\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"imdbId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8740\u001b[0m         )\n\u001b[1;32m-> 8741\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/603797576.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlink_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerateLink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"imdbId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tconst\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgenerateMovieId\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"imdbId\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generateLink' is not defined"
     ]
    }
   ],
   "source": [
    "link_df[\"url\"] = link_df.apply(lambda x: generateLink(x[\"imdbId\"]), axis=1)\n",
    "link_df[\"tconst\"] = link_df.apply(lambda x: generateMovieId(x[\"imdbId\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_df.to_csv(\"movie_url.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "row_names = ['movieId','imdbId', 'tmdbId', 'url']\n",
    "with open('movie_url.csv', 'r', newline='') as in_csv:\n",
    "    reader = csv.DictReader(in_csv, fieldnames=row_names, delimiter=',')\n",
    "    for row in reader:\n",
    "        movie_id = row['movieId']\n",
    "        movie_url = row['url']\n",
    "        domain = 'http://www.imdb.com'\n",
    "        with urllib.request.urlopen(movie_url) as response:\n",
    "            html = response.read()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # Get url of poster image\n",
    "            try:\n",
    "                image_url = soup.find('div', class_='poster').a.img['src']\n",
    "                # TODO: Replace hardcoded extension with extension from string itself\n",
    "                extension = '.jpg'\n",
    "                image_url = ''.join(image_url.partition('_')[0]) + extension\n",
    "                filename = 'img/' + movie_id + extension\n",
    "                print(\"test\")\n",
    "                print(filename)\n",
    "                with urllib.request.urlopen(image_url) as response:\n",
    "                    with open(filename, 'wb') as out_image:\n",
    "                        out_image.write(response.read())\n",
    "                    with open('movie_poster.csv', 'a', newline='') as out_csv:\n",
    "                        writer = csv.writer(out_csv, delimiter=',')\n",
    "                        writer.writerow([movie_id, image_url])\n",
    "            # Ignore cases where no poster image is present\n",
    "            except AttributeError:\n",
    "                print(\"error\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = ['movie_id', 'movie_url']\n",
    "with open('movie_url.csv', 'r', newline='') as in_csv:\n",
    "    reader = csv.DictReader(in_csv, fieldnames=row_names, delimiter=',')\n",
    "    for row in reader:\n",
    "        movie_id = row['movie_id']\n",
    "        movie_url = row['movie_url']\n",
    "        domain = 'http://www.imdb.com'\n",
    "        with urllib.request.urlopen(movie_url) as response:\n",
    "            html = response.read()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # Get url of poster image\n",
    "            try:\n",
    "                image_url = soup.find('div', class_='poster').a.img['src']\n",
    "                # TODO: Replace hardcoded extension with extension from string itself\n",
    "                extension = '.jpg'\n",
    "                image_url = ''.join(image_url.partition('_')[0]) + extension\n",
    "                filename = 'img/' + movie_id + extension\n",
    "                with urllib.request.urlopen(image_url) as response:\n",
    "                    with open(filename, 'wb') as out_image:\n",
    "                        out_image.write(response.read())\n",
    "                    with open('movie_poster.csv', 'a', newline='') as out_csv:\n",
    "                        writer = csv.writer(out_csv, delimiter=',')\n",
    "                        writer.writerow([movie_id, image_url])\n",
    "            # Ignore cases where no poster image is present\n",
    "            except AttributeError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Try \n",
    "https://github.com/tomkeith/imdb-scraper/blob/master/imdb-scraper.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "    \n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "import time\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(string, num_type='int'):\n",
    "    '''\n",
    "    Function to strip all non-numeric characters from string and return int or float\n",
    "    INPUT - String to convert\n",
    "          - num_type: either 'int' or 'float'\n",
    "    OUTPUT - int or float type (returns original string if neither specified)\n",
    "    '''\n",
    "    if num_type == 'float':\n",
    "        x = float( re.sub(\"[^0-9]\", \"\", string ) )\n",
    "    elif num_type == 'int':\n",
    "        x = int( re.sub(\"[^0-9]\", \"\", string ) )\n",
    "    else:\n",
    "        x = string\n",
    "    return x\n",
    "\n",
    "\n",
    "def savePoster(imdb_id, img_url):\n",
    "    '''\n",
    "    Function that fetches and save the poster image from provided url\n",
    "    and saves it with the provided id (corresponding with IMDb).\n",
    "    Won't replace (or even fetch) if file already exists.\n",
    "    \n",
    "    INPUT:  id from imdb, url where to find image\n",
    "    OUTPUT: boolean flag if saved or not.\n",
    "    '''\n",
    "    import os.path\n",
    "    \n",
    "    # Get file extension\n",
    "    ext = img_url.split('.')[-1]\n",
    "    \n",
    "    # Check to see if I already have it\n",
    "    if os.path.isfile(f'posters/{imdb_id}.{ext}'):\n",
    "        return False\n",
    "    \n",
    "    # Get image data, and save it as imdb_id\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))    \n",
    "    img.save(f'posters/{imdb_id}.{ext}')\n",
    "    \n",
    "    return True\n",
    "\n",
    "def concatenate_list_data(my_list):\n",
    "    result = ''\n",
    "    for element in my_list:\n",
    "        result += str(element)\n",
    "    return result\n",
    "\n",
    "def time_since(start_time):\n",
    "    '''\n",
    "    Simple timer calculating time difference between\n",
    "    start_time input parameter, and now\n",
    "    \n",
    "    OUTPUT: string ' 2m45s'\n",
    "    INPUT: timestamp of starting time\n",
    "    '''\n",
    "    end_time = time.time()\n",
    "    mins = (end_time - start_time)//60\n",
    "    secs = (end_time - start_time) - (60*mins)\n",
    "    return f'{mins:2.0f}m{secs:2.0f}s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_scrape(imdb_id,movie_id,  save_image=False, debug=False):\n",
    "    '''\n",
    "    Function which scrapes IMDb using IMDb ID 'tt0107290'. Second parameter is for \n",
    "    the movie poster (saved in /posters/ folder). Third parameter is to print result.\n",
    "    \n",
    "    This function is mean to be used in a loop. As such, the print outputs may lack\n",
    "    meaning if used outside of the cells below.\n",
    "    \n",
    "    INPUT:  - ID of movie to scrape from IMDB e.g. \"tt0076759\"\n",
    "            - boolean to save the movie poster or not (default True)\n",
    "            - boolean to print result\n",
    "           \n",
    "    OUTPUT: Dictionary of various scrapped information.\n",
    "    \n",
    "             {'tconst':imdb_id, 'title':'',     'release_year':'',     'release_date':'',\n",
    "              'MPAA':'',        'genre':[],     'runtime':'',          'poster_url':'',\n",
    "              'plot_short':'',  'plot_long':'', 'imdb_rating':'',      'num_imdb_votes':'',\n",
    "              'metacritic':'',  'num_user_reviews':'',                 'num_critic_reviews':''\n",
    "             }\n",
    "    '''\n",
    "    # Target datapoints to scrape (with provided imdb_id)\n",
    "    imdb_info_dict = {'movieid':movie_id, 'tconst':imdb_id,'title':'',  \n",
    "                      'MPAA':'',       'genre':[],            'poster_url':'',\n",
    "                      'description':'','reviewBody':'','keywords': '', 'imdb_rating':'',      'num_imdb_votes':'',\n",
    "                     }\n",
    "    imdb_info_dict['tconst'] = imdb_id\n",
    "    \n",
    "    imdb_base_url = 'https://www.imdb.com/title/'\n",
    "    print(f'{imdb_id.ljust(10)} ', end='')\n",
    "    \n",
    "    # Main content - build URL, and soup content\n",
    "    imdb_full_url = imdb_base_url + imdb_id\n",
    "    r = requests.get(imdb_full_url).content\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    print(f'[x]   ', end='')\n",
    "    \n",
    "    # Code from js section has json variables\n",
    "    json_dict = json.loads( str( soup.findAll('script', {'type':'application/ld+json'})[0].text ))\n",
    "\n",
    "    # Info - Movie title, year, parental content rating, poster url\n",
    "    imdb_info_dict['title'] = json_dict['name']\n",
    "    if 'contentRating' in json_dict:\n",
    "        imdb_info_dict['MPAA'] = json_dict['contentRating'] \n",
    "    imdb_info_dict['poster_url'] = json_dict['image']\n",
    "    imdb_info_dict['description'] = json_dict['description']\n",
    "    imdb_info_dict['keywords'] = json_dict['keywords']\n",
    "\n",
    "    # imdb_info_dict['release_year'] = int( soup.find('span', {'id':'titleYear'}).a.text )\n",
    "    # imdb_info_dict['runtime'] = to_numeric( soup.find('time')['datetime'] )\n",
    "\n",
    "\n",
    "    # Release date (from top header)\n",
    "    # date_string = soup.find('div', {'class':'title_wrapper'}).findAll('a')[-1].text.split(' (')[0]\n",
    "    # imdb_info_dict['release_date'] = date_string\n",
    "    \n",
    "    # Genres (up to 7)\n",
    "    imdb_info_dict['genre'] = json_dict['genre']\n",
    "\n",
    "    # Ratings - IMDb rating (and vote count), Metacritic\n",
    "    imdb_info_dict['imdb_rating'] = float( json_dict['aggregateRating']['ratingValue'] )\n",
    "    imdb_info_dict['num_imdb_votes'] = json_dict['aggregateRating']['ratingCount']\n",
    "\n",
    "    # Metacritic score, if there is one\n",
    "    # if soup.find('div', {'class':'metacriticScore'}) != None:\n",
    "    #     imdb_info_dict['metacritic'] = int( soup.find('div', {'class':'metacriticScore'}).span.text )\n",
    "\n",
    "    # Reviews - Number of critic and public reviews (different than ratings/votes)\n",
    "    num_review_list = soup.findAll('div',{'class':'titleReviewBarItem titleReviewbarItemBorder'})\n",
    "    if num_review_list != []:\n",
    "        reviews = num_review_list[0].findAll('a')\n",
    "        if len(reviews) > 1:\n",
    "            imdb_info_dict['num_critic_reviews'] = to_numeric( reviews[1].text )\n",
    "        if len(reviews) > 0:\n",
    "            imdb_info_dict['num_user_reviews'] = to_numeric( reviews[0].text )\n",
    "\n",
    "    # Plots - long and short versions\n",
    "    # imdb_info_dict['plot_short'] = soup.find('div',{'class':'summary_text'}).text.strip()\n",
    "    # if 'Add a Plot' in imdb_info_dict['plot_short']:\n",
    "    #     imdb_info_dict['plot_short'] = ''\n",
    "    # if soup.find('div',{'id':'titleStoryLine'}).div.p != None:\n",
    "    #     imdb_info_dict['plot_long'] = soup.find('div',{'id':'titleStoryLine'}).div.p.span.text.strip()\n",
    "    \n",
    "    # Plot output\n",
    "    print(f'[x]   ', end='')\n",
    "\n",
    "    if save_image == True:\n",
    "        img_status = savePoster(imdb_id, imdb_info_dict['poster_url'])\n",
    "        if img_status == True:\n",
    "            print(f'[x]   ', end='')\n",
    "        else:\n",
    "            print(f'[ ]   ', end='')\n",
    "    else:\n",
    "        print(f'N/A   ', end='')\n",
    "    \n",
    "    print(f\"{(imdb_info_dict['title']+' ('')')[:100]:100} \", end='')\n",
    "    # time.sleep(random.randint(1,10) / \n",
    "    \n",
    "    print('')\n",
    "    if(debug):\n",
    "        pprint(imdb_info_dict)\n",
    "    return imdb_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def scrapeMovies(startInterval, endInterval): \n",
    "    # xNeed to provide a csv of IMDb IDs to scrape\n",
    "    movie_df = pd.read_csv('movie_url.csv')\n",
    "\n",
    "    failed_list = []\n",
    "\n",
    "\n",
    "    print('--------------------------------------------------------------------------')    \n",
    "    print('')\n",
    "    print('Count   tconst     Get   Parse Img   Title')\n",
    "\n",
    "    start_time = time.time()\n",
    "    annual_movie_list = []\n",
    "    fails=0\n",
    "    for i, tconst in enumerate(movie_df.iloc[startInterval:endInterval,:]['tconst'].values):\n",
    "        print(f'{i+1:5d}   ', end = '')\n",
    "        try:\n",
    "            movie_id =str(int(movie_df[movie_df[\"tconst\"]==tconst][\"movieId\"]))\n",
    "            scraped_movie_info = imdb_scrape(tconst, movie_id, False) #Change to false to NOT save movie poster\n",
    "            annual_movie_list.append(scraped_movie_info)\n",
    "        except Exception:\n",
    "            print(f'--------- FAILED ---------- FAILED ---------- FAILED ----------')\n",
    "            failed_list.append(tconst)\n",
    "            fails+=1\n",
    "\n",
    "    print(f'Movies scraped: {len(annual_movie_list)}   Fails: {fails}   ', end='')\n",
    "    my_df = pd.DataFrame(annual_movie_list)\n",
    "\n",
    "    #Load old df \n",
    "    oldDf = pd.read_csv('imdb_scrape.csv', delimiter='\\t')\n",
    "    newDF = my_df.append(oldDf, ignore_index=True)\n",
    "    newDF.to_csv(f'imdb_scrape.csv', sep='\\t', quoting=csv.QUOTE_ALL, index=False)\n",
    "    print('\\n')\n",
    "    print(f'Saved: imdb_scrape.csv     ', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "\n",
      "Count   tconst     Get   Parse Img   Title\n",
      "Movies scraped: 0   Fails: 0   \n",
      "\n",
      "Saved: imdb_scrape.csv     \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Count   tconst     Get   Parse Img   Title\n",
      "    1   tt0317842  [x]   [x]   N/A   Knafayim Shvurot ()                                                                                  \n",
      "    2   tt0329767  [x]   [x]   N/A   Wilbur Wants to Kill Himself ()                                                                      \n",
      "    3   tt0107473  [x]   [x]   N/A   Mad Dog and Glory ()                                                                                 \n",
      "    4   tt50839    [x]   --------- FAILED ---------- FAILED ---------- FAILED ----------\n",
      "    5   tt0363547  [x]   [x]   N/A   Dawn of the Dead ()                                                                                  \n",
      "    6   tt0338013  [x]   [x]   N/A   Eternal Sunshine of the Spotless Mind ()                                                             \n",
      "    7   tt0364045  [x]   [x]   N/A   Taking Lives ()                                                                                      \n",
      "    8   tt0332658  [x]   [x]   N/A   Intermission ()                                                                                      \n",
      "    9   tt0300051  [x]   [x]   N/A   Jersey Girl ()                                                                                       \n",
      "   10   tt0335245  [x]   [x]   N/A   The Ladykillers ()                                                                                   \n",
      "Movies scraped: 9   Fails: 1   \n",
      "\n",
      "Saved: imdb_scrape.csv     \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Count   tconst     Get   Parse Img   Title\n",
      "    1   tt0354766  [x]   [x]   N/A   Never Die Alone ()                                                                                   \n",
      "    2   tt0331632  [x]   [x]   N/A   Scooby-Doo 2: Monsters Unleashed ()                                                                  \n",
      "    3   tt0276919  [x]   [x]   N/A   Dogville ()                                                                                          \n",
      "    4   tt0277941  "
     ]
    }
   ],
   "source": [
    "max = 9743\n",
    "current_progress = 4904\n",
    "iteration = list(np.arange(current_progress,9743, 10))\n",
    "lastElement = current_progress +1\n",
    "for currentElement in iteration: \n",
    "    scrapeMovies(lastElement, currentElement)\n",
    "    lastElement = currentElement\n",
    "    \n",
    "\n",
    "\n",
    "scrapeMovies(lastElement, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 100,\n",
       " 200,\n",
       " 300,\n",
       " 400,\n",
       " 500,\n",
       " 600,\n",
       " 700,\n",
       " 800,\n",
       " 900,\n",
       " 1000,\n",
       " 1100,\n",
       " 1200,\n",
       " 1300,\n",
       " 1400,\n",
       " 1500,\n",
       " 1600,\n",
       " 1700,\n",
       " 1800,\n",
       " 1900,\n",
       " 2000,\n",
       " 2100,\n",
       " 2200,\n",
       " 2300,\n",
       " 2400,\n",
       " 2500,\n",
       " 2600,\n",
       " 2700,\n",
       " 2800,\n",
       " 2900,\n",
       " 3000,\n",
       " 3100,\n",
       " 3200,\n",
       " 3300,\n",
       " 3400,\n",
       " 3500,\n",
       " 3600,\n",
       " 3700,\n",
       " 3800,\n",
       " 3900,\n",
       " 4000,\n",
       " 4100,\n",
       " 4200,\n",
       " 4300,\n",
       " 4400,\n",
       " 4500,\n",
       " 4600,\n",
       " 4700,\n",
       " 4800,\n",
       " 4900,\n",
       " 5000,\n",
       " 5100,\n",
       " 5200,\n",
       " 5300,\n",
       " 5400,\n",
       " 5500,\n",
       " 5600,\n",
       " 5700,\n",
       " 5800,\n",
       " 5900,\n",
       " 6000,\n",
       " 6100,\n",
       " 6200,\n",
       " 6300,\n",
       " 6400,\n",
       " 6500,\n",
       " 6600,\n",
       " 6700,\n",
       " 6800,\n",
       " 6900,\n",
       " 7000,\n",
       " 7100,\n",
       " 7200,\n",
       " 7300,\n",
       " 7400,\n",
       " 7500,\n",
       " 7600,\n",
       " 7700,\n",
       " 7800,\n",
       " 7900,\n",
       " 8000,\n",
       " 8100,\n",
       " 8200,\n",
       " 8300,\n",
       " 8400,\n",
       " 8500,\n",
       " 8600,\n",
       " 8700,\n",
       " 8800,\n",
       " 8900,\n",
       " 9000,\n",
       " 9100,\n",
       " 9200,\n",
       " 9300,\n",
       " 9400,\n",
       " 9500,\n",
       " 9600,\n",
       " 9700]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.arange(0,9743, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "\n",
      "Count   tconst     Get   Parse Img   Title\n",
      "    1   tt0114709  [x]   [x]   N/A   Toy Story ()                                                                                         \n",
      "    2   tt0113497  [x]   [x]   N/A   Jumanji ()                                                                                           \n",
      "    3   tt0113228  [x]   [x]   N/A   Grumpier Old Men ()                                                                                  \n",
      "    4   tt0114885  [x]   [x]   N/A   Waiting to Exhale ()                                                                                 \n",
      "    5   tt0113041  [x]   [x]   N/A   Father of the Bride Part II ()                                                                       \n",
      "    6   tt0113277  [x]   [x]   N/A   Heat ()                                                                                              \n",
      "    7   tt0114319  [x]   [x]   N/A   Sabrina ()                                                                                           \n",
      "    8   tt0112302  [x]   [x]   N/A   Tom and Huck ()                                                                                      \n",
      "    9   tt0114576  [x]   [x]   N/A   Sudden Death ()                                                                                      \n",
      "   10   tt0113189  [x]   [x]   N/A   GoldenEye ()                                                                                         \n",
      "   11   tt0112346  [x]   [x]   N/A   The American President ()                                                                            \n",
      "   12   tt0112896  [x]   [x]   N/A   Dracula: Dead and Loving It ()                                                                       \n",
      "   13   tt0112453  [x]   [x]   N/A   Balto ()                                                                                             \n",
      "   14   tt0113987  [x]   [x]   N/A   Nixon ()                                                                                             \n",
      "   15   tt0112760  [x]   [x]   N/A   Cutthroat Island ()                                                                                  \n",
      "   16   tt0112641  [x]   [x]   N/A   Casino ()                                                                                            \n",
      "   17   tt0114388  [x]   [x]   N/A   Sense and Sensibility ()                                                                             \n",
      "   18   tt0113101  [x]   [x]   N/A   Four Rooms ()                                                                                        \n",
      "   19   tt0112281  [x]   [x]   N/A   Ace Ventura: When Nature Calls ()                                                                    \n",
      "   20   tt0113845  [x]   [x]   N/A   Money Train ()                                                                                       \n",
      "   21   tt0113161  [x]   [x]   N/A   Get Shorty ()                                                                                        \n",
      "   22   tt0112722  [x]   [x]   N/A   Copycat ()                                                                                           \n",
      "   23   tt0112401  [x]   [x]   N/A   Assassins ()                                                                                         \n",
      "   24   tt0114168  [x]   [x]   N/A   Powder ()                                                                                            \n",
      "   25   tt0113627  [x]   [x]   N/A   Leaving Las Vegas ()                                                                                 \n",
      "   26   tt0114057  [x]   [x]   N/A   Othello ()                                                                                           \n",
      "   27   tt0114011  [x]   [x]   N/A   Now and Then ()                                                                                      \n",
      "   28   tt0114117  [x]   [x]   N/A   Persuasion ()                                                                                        \n",
      "   29   tt0112682  [x]   [x]   N/A   La cité des enfants perdus ()                                                                        \n",
      "   30   tt0115012  [x]   [x]   N/A   Yao a yao, yao dao wai po qiao ()                                                                    \n",
      "   31   tt0112792  [x]   [x]   N/A   Dangerous Minds ()                                                                                   \n",
      "   32   tt0114746  [x]   [x]   N/A   Twelve Monkeys ()                                                                                    \n",
      "   33   tt0112431  [x]   [x]   N/A   Babe ()                                                                                              \n",
      "   34   tt0112818  [x]   [x]   N/A   Dead Man Walking ()                                                                                  \n",
      "   35   tt0113442  [x]   [x]   N/A   It Takes Two ()                                                                                      \n",
      "   36   tt0112697  [x]   [x]   N/A   Clueless ()                                                                                          \n",
      "   37   tt0112749  [x]   [x]   N/A   Cry, the Beloved Country ()                                                                          \n",
      "   38   tt0114279  [x]   [x]   N/A   Richard III ()                                                                                       \n",
      "   39   tt0112819  [x]   [x]   N/A   Dead Presidents ()                                                                                   \n",
      "   40   tt0114272  [x]   [x]   N/A   Restoration ()                                                                                       \n",
      "   41   tt0113855  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/700922701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{i+1:5d}   '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mscraped_movie_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimdb_scrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Change to false to NOT save movie poster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mannual_movie_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscraped_movie_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/220377119.py\u001b[0m in \u001b[0;36mimdb_scrape\u001b[1;34m(imdb_id, save_image, debug)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# Main content - build URL, and soup content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mimdb_full_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimdb_base_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimdb_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimdb_full_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'[x]   '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m             \u001b[1;31m# Redirect resolving generator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    665\u001b[0m             \u001b[1;31m# Redirect resolving generator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 resp = self.send(\n\u001b[0m\u001b[0;32m    238\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\StudiumVenv\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "# xNeed to provide a csv of IMDb IDs to scrape\n",
    "movie_df = pd.read_csv('movie_url.csv')\n",
    "\n",
    "failed_list = []\n",
    "\n",
    "\n",
    "print('--------------------------------------------------------------------------')    \n",
    "print('')\n",
    "print('Count   tconst     Get   Parse Img   Title')\n",
    "\n",
    "start_time = time.time()\n",
    "annual_movie_list = []\n",
    "fails=0\n",
    "\n",
    "# for i, tconst in enumerate(movie_df.iloc[0:5, :]['tconst'].values):\n",
    "for i, tconst in enumerate(movie_df['tconst'].values):\n",
    "    print(f'{i+1:5d}   ', end = '')\n",
    "    try:\n",
    "        scraped_movie_info = imdb_scrape(tconst, False) #Change to false to NOT save movie poster\n",
    "        annual_movie_list.append(scraped_movie_info)\n",
    "    except Exception:\n",
    "        print(f'--------- FAILED ---------- FAILED ---------- FAILED ----------')\n",
    "        failed_list.append(tconst)\n",
    "        fails+=1\n",
    "\n",
    "print(f'Movies scraped: {len(annual_movie_list)}   Fails: {fails}   ', end='')\n",
    "\n",
    "my_df = pd.DataFrame(annual_movie_list)\n",
    "my_df.to_csv(f'imdb_scrape.csv', sep='\\t', quoting=csv.QUOTE_ALL, index=False)\n",
    "print('\\n')\n",
    "print(f'Saved: imdb_scrape.csv     ', end='')\n",
    "print(f'Time taken: {time_since(start_time)}')\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59197d1c7420480de6a1665d1e6d18e2df0c0a7095d9d94042b025d7141db809"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('StudiumVenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
